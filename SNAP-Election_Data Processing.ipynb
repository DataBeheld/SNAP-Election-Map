{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc63d7e2-8358-4850-bf00-115c44f538cf",
   "metadata": {},
   "source": [
    "# Clean and process data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23fb0c8-a785-4b7e-add5-af34b9a46808",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af40ce4b-d578-40aa-a216-8ac0c3cb38ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb33e61e-517c-40bf-96b8-b66a1c25362a",
   "metadata": {},
   "source": [
    "## Generate and process Congressional District geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "791b6ecb-5f29-49de-922c-16b4c528c3ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPSG:4326\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "#read in file\n",
    "#https://geodata.bts.gov/datasets/usdot::congressional-districts/explore\n",
    "gdf_0 = gpd.read_file('data/NTAD_Congressional_Districts_1928759543695387395.geojson')\n",
    "\n",
    "\n",
    "#add columns as needed\n",
    "gdf_0['FIPSNUM'] = gdf_0['STATEFP'].astype(int)\n",
    "\n",
    "\n",
    "#create new GDF filtered on voting districts (still includes D.C.)\n",
    "gdf_0 = gdf_0[(gdf_0['FIPSNUM'] < 57)&(gdf_0['FIPSNUM'] != 3)&(gdf_0['FIPSNUM'] != 7)\n",
    "    &(gdf_0['FIPSNUM'] != 14)&(gdf_0['FIPSNUM'] != 43)&(gdf_0['FIPSNUM'] != 52)]\n",
    "\n",
    "\n",
    "#validate CRS and that the GDF is still a valid coverage\n",
    "print(gdf_0.crs)\n",
    "print(gdf_0.is_valid_coverage())\n",
    "\n",
    "\n",
    "#simplify the geometry for loading speed\n",
    "#this will generate a SettingWithCopyWarning, but this is behaving as intended\n",
    "gdf_0['geometry'] = gdf_0.loc[:, 'geometry'].simplify_coverage(0.005).buffer(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9330e522-2dd6-4589-97c6-1c18669e89e5",
   "metadata": {},
   "source": [
    "## Generate and process SNAP data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "63ebaab5-490f-4e7d-855c-9a73d2bd65a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in file\n",
    "#https://www.fns.usda.gov/sites/default/files/data-files/cat-snap-congressional-district-data-export.xlsx\n",
    "sdf = pd.read_excel('data/cat-snap-congressional-district-data-export.xlsx', dtype={'fipscd': str, 'fips': str})\n",
    "\n",
    "\n",
    "#set FIPS codes as strings for merge\n",
    "sdf['fipscd'] = sdf['fipscd'].astype('string')\n",
    "sdf['fips'] = sdf['fips'].astype('string')\n",
    "\n",
    "\n",
    "#merge SNAP data into GeoDataFrame\n",
    "gdf_s = gdf_0.merge(sdf, how='left', left_on='GEOID', right_on='fipscd', validate='1:1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "620fb34b-ec15-40a4-98eb-7d384da5f8ba",
   "metadata": {},
   "source": [
    "## Generate and process election data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c4e23b23-7413-4a35-a6e0-3c493b3f6aec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Connor\\AppData\\Local\\Temp\\ipykernel_9300\\2849011101.py:3: DtypeWarning: Columns (9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  edf = pd.read_csv('data/1976-2024-house.tab')\n"
     ]
    }
   ],
   "source": [
    "#read in file\n",
    "#https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/IG0UN2\n",
    "#returns a mixed type warning, but we are dropping the column in question later anyways\n",
    "edf = pd.read_csv('data/1976-2024-house.tab')\n",
    "\n",
    "\n",
    "#filter to most recent midterms, create match key, and rename column so there isn't any confusion in merge\n",
    "edf = edf[edf['year'] == 2022]\n",
    "edf['GEOID'] = edf['state_fips'].astype(str).str.zfill(2) + edf['district'].astype(str).str.zfill(2)\n",
    "edf = edf.rename(columns={'party': 'party_delete'})\n",
    "\n",
    "\n",
    "#clean up for merge\n",
    "columns_remove_1 = ['year', 'state', 'state_po', 'state_fips', 'state_cen', 'state_ic', 'office', 'district', 'stage', 'runoff', \n",
    "                    'special', 'candidate', 'writein', 'mode', 'totalvotes', 'unofficial', 'version', 'fusion_ticket']\n",
    "\n",
    "edf = edf.drop(columns = columns_remove_1)\n",
    "\n",
    "\n",
    "#merge election data into GeoDataFrame\n",
    "#because of its format, we need to do two sweeps of the election data to populate two different columns\n",
    "gdf_prefips = gdf_s.merge(edf[edf['party_delete'] == 'REPUBLICAN'].groupby('GEOID').sum(), how='left', on='GEOID', validate='1:1')\n",
    "gdf_prefips = gdf_prefips.rename(columns={'candidatevotes': 'R votes'})\n",
    "\n",
    "gdf_prefips = gdf_prefips.merge(edf[edf['party_delete'] == 'DEMOCRAT'].groupby('GEOID').sum(), how='left', on='GEOID', validate='1:1')\n",
    "gdf_prefips = gdf_prefips.rename(columns={'candidatevotes': 'D votes'})\n",
    "\n",
    "\n",
    "#clean up and reduce size\n",
    "columns_remove_2 = ['LSAD', 'CDSESSN', 'MTFCC', 'FUNCSTAT', 'OFFICE_ID', 'BIOGUIDE_ID', 'OFFICE_AUDIT_ID', 'PREFIX', 'FIRSTNAME', \n",
    "       'MIDDLENAME', 'LASTNAME', 'SUFFIX', 'LISTING_NAME', 'PHONE', 'WEBSITEURL', 'VACANT', 'CONTACTFORMURL', 'PHOTOURL', 'FACE_BOOK_URL', \n",
    "       'TWITTER_URL', 'YOUTUBE_URL', 'INSTAGRAM_URL', 'FLICKR_URL', 'VACANCY', 'ROOM_NUM', 'HOB', 'COMMITTEE_ASSIGNMENTS', 'LAST_UPDATED', \n",
    "       'hh_poverty_pct_in_snap', 'hh_race_aian_pct_in_snap', 'hh_race_asian_pct_in_snap', 'hh_race_black_pct_in_snap',\n",
    "       'hh_race_hisp_pct_in_snap', 'hh_race_nhpi_pct_in_snap', 'hh_race_other_pct_in_snap', 'hh_race_twoplus_pct_in_snap', \n",
    "       'hh_race_white_pct_in_snap', 'hh_60plus_pct', 'hh_snap_60plus', 'hh_snap_60plus_pct', 'hh_snap_children', 'hh_snap_children_pct', \n",
    "       'hh_snap_disabled', 'hh_snap_disabled_pct', 'hh_snap_poverty', 'hh_snap_poverty_pct', 'hh_snap_race_aian', 'hh_snap_race_aian_pct', \n",
    "       'hh_snap_race_asian', 'hh_snap_race_asian_pct', 'hh_snap_race_black', 'hh_snap_race_black_pct', 'hh_snap_race_hisp', \n",
    "       'hh_snap_race_hisp_pct', 'hh_snap_race_nhpi', 'hh_snap_race_nhpi_pct', 'hh_snap_race_other', 'hh_snap_race_other_pct', \n",
    "       'hh_snap_race_twoplus', 'hh_snap_race_twoplus_pct', 'hh_snap_race_white', 'hh_snap_race_white_pct', 'hh_total_60plus', \n",
    "       'hh_total_disabled', 'hh_total_disabled_pct', 'hh_total_poverty', 'hh_total_poverty_pct', 'hh_total_race_aian', \n",
    "       'hh_total_race_aian_pct', 'hh_total_race_asian', 'hh_total_race_asian_pct', 'hh_total_race_black', 'hh_total_race_black_pct', \n",
    "       'hh_total_race_hisp', 'hh_total_race_hisp_pct', 'hh_total_race_nhpi', 'hh_total_race_nhpi_pct', 'hh_total_race_other', \n",
    "       'hh_total_race_other_pct', 'hh_total_race_twoplus', 'hh_total_race_twoplus_pct', 'hh_total_race_white', 'hh_total_race_white_pct', \n",
    "       'medhhinc', 'party_delete_x', 'party_delete_y']\n",
    "\n",
    "gdf_prefips = gdf_prefips.drop(columns = columns_remove_2)\n",
    "\n",
    "\n",
    "#zero out NaNs and recalculate PARTY\n",
    "gdf_prefips['R votes'] = gdf_prefips['R votes'].fillna(0)\n",
    "gdf_prefips['D votes'] = gdf_prefips['D votes'].fillna(0)\n",
    "\n",
    "gdf_prefips['PARTY'] = np.where(gdf_prefips['D votes'] > gdf_prefips['R votes'], 'D', 'R')\n",
    "gdf_prefips['PARTYNUM'] = np.where(gdf_prefips['PARTY'] == 'R', 1, -1)\n",
    "\n",
    "\n",
    "#sort for pie chart\n",
    "gdf_prefips = gdf_prefips.sort_values(by=['PARTY', 'hh_snap'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb7a0c9-d205-4152-ba21-17d0b59973ad",
   "metadata": {},
   "source": [
    "## Create FIPS mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1471348d-e8c9-4467-bcc6-c89ee01fd4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import base state data and clean\n",
    "states_df = pd.read_csv('https://www2.census.gov/geo/docs/reference/codes2020/national_state2020.txt', sep='|')\n",
    "states_df = states_df[states_df['STATEFP'] < 57]\n",
    "states_df['FIPS'] = states_df['STATEFP'].astype(str).str.zfill(2)\n",
    "states_df = states_df.drop(columns = ['STATE', 'STATEFP', 'STATENS'])\n",
    "\n",
    "\n",
    "#create additional geographies\n",
    "usa_df = pd.DataFrame({'STATE_NAME': ['All U.S.', '---STATES---'], 'FIPS': ['USA', '--']})\n",
    "regions_df = pd.DataFrame({'STATE_NAME': ['---REGIONS---', 'Northeast Region', 'Midwest Region', 'South Region', 'West Region'], 'FIPS': ['--', 'R01', 'R02', 'R03', 'R04']})\n",
    "divs_df = pd.DataFrame({'STATE_NAME': ['---DIVISIONS---', 'New England Div.', 'Middle Atlantic Div.', 'East North Central Div.', 'West North Central Div.', 'South Atlantic Div.', 'East South Central Div.', 'West South Central Div.', 'Mountain Div.', 'Pacific Div.'], 'FIPS': ['--', 'D01', 'D02', 'D03', 'D04', 'D05', 'D06', 'D07', 'D08', 'D09']})\n",
    "\n",
    "\n",
    "#append and save out fips_df for use in pie chart title\n",
    "fips_df = pd.concat([usa_df, states_df, regions_df, divs_df], ignore_index=True)\n",
    "fips_df.to_csv('data/fips.csv', index=False)\n",
    "\n",
    "\n",
    "#set region and division code lists for each state to be merged in\n",
    "reg_codes = pd.Series(['--', '--','R03', '--', 'R04', 'R03', 'R04', 'R04', 'R01', 'R03', 'R03', 'R03', 'R03', '--', 'R04', 'R02', 'R02', 'R02', 'R02', 'R03', 'R03', 'R01', 'R03', 'R01', 'R02', 'R02', 'R03', 'R02', 'R04', 'R02', 'R04', 'R01', 'R01', 'R04', 'R01', 'R03', 'R02', 'R02', 'R03', 'R04', 'R01', 'R01', 'R03', 'R02', 'R03', 'R03', 'R04', 'R01', 'R03', 'R04', 'R03', 'R02', 'R04'], copy=False)\n",
    "div_codes = pd.Series(['--', '--','D06', '--', 'D08', 'D07', 'D09', 'D08', 'D01', 'D05', 'D05', 'D05', 'D05', '--', 'D08', 'D03', 'D03', 'D04', 'D04', 'D06', 'D07', 'D01', 'D05', 'D01', 'D03', 'D04', 'D06', 'D04', 'D08', 'D04', 'D08', 'D01', 'D02', 'D08', 'D02', 'D05', 'D04', 'D03', 'D07', 'D09', 'D02', 'D01', 'D05', 'D04', 'D06', 'D07', 'D08', 'D01', 'D05', 'D09', 'D05', 'D03', 'D08'], copy=False)\n",
    "\n",
    "\n",
    "#append region/division columns to fips_df\n",
    "fips_df['reg_codes'] = reg_codes\n",
    "fips_df['div_codes'] = div_codes\n",
    "fips_df = fips_df.fillna('--')\n",
    "\n",
    "\n",
    "#merge in region/division codes to gdf\n",
    "gdf_final = gdf_prefips.merge(fips_df[fips_df['FIPS'] != '--'], how='left', left_on='STATEFP', right_on='FIPS', validate='m:1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206be6c4-96e5-4e31-8514-008ede681fa5",
   "metadata": {},
   "source": [
    "## Save out processed data as GeoJSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f56be125-219b-4f4e-aed6-c7d8aac0799b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_final.to_file('data/processed.geojson', driver='GeoJSON')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
